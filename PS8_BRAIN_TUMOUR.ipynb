{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuqmGAacxgaPOHU1nXSJND"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6u1DrKWQZ9F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Set the path to your brain tumor dataset\n",
        "data_path = 'path/to/your_brain_tumor_dataset/'\n",
        "\n",
        "# Load metadata containing image paths and labels\n",
        "metadata = pd.read_csv(os.path.join(data_path, 'metadata.csv'))\n",
        "\n",
        "# Encode labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "metadata['encoded_labels'] = label_encoder.fit_transform(metadata['Label'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_metadata, test_metadata = train_test_split(metadata, test_size=0.2, random_state=42, stratify=metadata['encoded_labels'])\n",
        "\n",
        "# Create ImageDataGenerators for training and testing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow data from the directory and apply data augmentation\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=train_metadata, directory=data_path,\n",
        "                                                    x_col='filename', y_col='Label', target_size=(150, 150),\n",
        "                                                    class_mode='categorical', batch_size=32, shuffle=True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=test_metadata, directory=data_path,\n",
        "                                                  x_col='filename', y_col='Label', target_size=(150, 150),\n",
        "                                                  class_mode='categorical', batch_size=32, shuffle=False)\n",
        "\n",
        "# Build a CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks (optional but recommended)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10, validation_data=test_generator, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "\n",
        "# Save the model\n",
        "model.save('brain_tumor_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Set the path to your brain tumor dataset\n",
        "data_path = 'path/to/your_brain_tumor_dataset/'\n",
        "\n",
        "# Get the list of subdirectories (each subdirectory corresponds to a class)\n",
        "class_names = sorted(os.listdir(data_path))\n",
        "\n",
        "# Create a DataFrame to store file paths and corresponding labels\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_path = os.path.join(data_path, class_name)\n",
        "    class_files = os.listdir(class_path)\n",
        "\n",
        "    file_paths.extend([os.path.join(class_path, file) for file in class_files])\n",
        "    labels.extend([class_name] * len(class_files))\n",
        "\n",
        "df = pd.DataFrame({'filename': file_paths, 'Label': labels})\n",
        "\n",
        "# Encode labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['encoded_labels'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['encoded_labels'])\n",
        "\n",
        "# Create ImageDataGenerators for training and testing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow data from the directory and apply data augmentation\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df, directory=None,\n",
        "                                                    x_col='filename', y_col='Label', target_size=(150, 150),\n",
        "                                                    class_mode='categorical', batch_size=32, shuffle=True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df, directory=None,\n",
        "                                                  x_col='filename', y_col='Label', target_size=(150, 150),\n",
        "                                                  class_mode='categorical', batch_size=32, shuffle=False)\n",
        "\n",
        "# Build a CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks (optional but recommended)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10, validation_data=test_generator, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "\n",
        "# Save the model\n",
        "model.save('brain_tumor_model.h5')\n"
      ],
      "metadata": {
        "id": "e46ir2o9QvMU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}