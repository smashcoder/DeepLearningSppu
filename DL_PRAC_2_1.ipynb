{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smashcoder/DeepLearningSppu/blob/main/DL_PRAC_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZobIbYB4SXyk"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ya_SWtISic9",
        "outputId": "e45ffe47-8728-46ab-f4c9-e22e663862ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] accessing MNIST...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-o\", \"--output\", required=True,\n",
        "#help=\"path to the output loss/accuracy plot\")\n",
        "#args = vars(ap.parse_args())\n",
        "# grab the MNIST dataset (if this is your first time using this\n",
        "# dataset then the 11MB download may take a minute)\n",
        "print(\"[INFO] accessing MNIST...\")\n",
        "((trainX, trainY), (testX, testY)) = mnist.load_data()\n",
        "# each image in the MNIST dataset is represented as a 28x28x1\n",
        "# image, but in order to apply a standard neural network we must\n",
        "# first \"flatten\" the image to be simple list of 28x28=784 pixels\n",
        "trainX = trainX.reshape((trainX.shape[0], 28 * 28 * 1))\n",
        "testX = testX.reshape((testX.shape[0], 28 * 28 * 1))\n",
        "xtest = testX.reshape((testX.shape[0],28,28))\n",
        "# scale data to the range of [0, 1]\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XCjLn1OZS2E2"
      },
      "outputs": [],
      "source": [
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UjQV0nriS6Vh",
        "outputId": "6e36c0d6-2e1b-414a-e7c3-54298c68aa4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/100\n",
            "469/469 [==============================] - 7s 4ms/step - loss: 2.2711 - accuracy: 0.2172 - val_loss: 2.2331 - val_accuracy: 0.2432\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.1966 - accuracy: 0.4008 - val_loss: 2.1530 - val_accuracy: 0.4531\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.1027 - accuracy: 0.5146 - val_loss: 2.0375 - val_accuracy: 0.5693\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.9653 - accuracy: 0.5679 - val_loss: 1.8714 - val_accuracy: 0.6154\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.7782 - accuracy: 0.6109 - val_loss: 1.6619 - val_accuracy: 0.6550\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.5642 - accuracy: 0.6525 - val_loss: 1.4468 - val_accuracy: 0.6879\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.3634 - accuracy: 0.6945 - val_loss: 1.2621 - val_accuracy: 0.7013\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.1978 - accuracy: 0.7246 - val_loss: 1.1157 - val_accuracy: 0.7396\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.0675 - accuracy: 0.7498 - val_loss: 0.9995 - val_accuracy: 0.7713\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9647 - accuracy: 0.7697 - val_loss: 0.9081 - val_accuracy: 0.7829\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.8820 - accuracy: 0.7869 - val_loss: 0.8330 - val_accuracy: 0.8053\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.8137 - accuracy: 0.8013 - val_loss: 0.7710 - val_accuracy: 0.8109\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.7564 - accuracy: 0.8130 - val_loss: 0.7182 - val_accuracy: 0.8204\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.7080 - accuracy: 0.8227 - val_loss: 0.6730 - val_accuracy: 0.8318\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6667 - accuracy: 0.8312 - val_loss: 0.6344 - val_accuracy: 0.8381\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6313 - accuracy: 0.8385 - val_loss: 0.6019 - val_accuracy: 0.8459\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6008 - accuracy: 0.8455 - val_loss: 0.5732 - val_accuracy: 0.8513\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5743 - accuracy: 0.8503 - val_loss: 0.5486 - val_accuracy: 0.8535\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5511 - accuracy: 0.8558 - val_loss: 0.5267 - val_accuracy: 0.8625\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5307 - accuracy: 0.8599 - val_loss: 0.5073 - val_accuracy: 0.8655\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5125 - accuracy: 0.8652 - val_loss: 0.4903 - val_accuracy: 0.8698\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4964 - accuracy: 0.8686 - val_loss: 0.4754 - val_accuracy: 0.8734\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4819 - accuracy: 0.8726 - val_loss: 0.4613 - val_accuracy: 0.8754\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4688 - accuracy: 0.8753 - val_loss: 0.4487 - val_accuracy: 0.8789\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4570 - accuracy: 0.8786 - val_loss: 0.4384 - val_accuracy: 0.8816\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4463 - accuracy: 0.8805 - val_loss: 0.4282 - val_accuracy: 0.8838\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4365 - accuracy: 0.8827 - val_loss: 0.4184 - val_accuracy: 0.8865\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4275 - accuracy: 0.8852 - val_loss: 0.4102 - val_accuracy: 0.8880\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4194 - accuracy: 0.8866 - val_loss: 0.4027 - val_accuracy: 0.8906\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4119 - accuracy: 0.8881 - val_loss: 0.3954 - val_accuracy: 0.8922\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4050 - accuracy: 0.8895 - val_loss: 0.3892 - val_accuracy: 0.8939\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3987 - accuracy: 0.8913 - val_loss: 0.3831 - val_accuracy: 0.8958\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3928 - accuracy: 0.8921 - val_loss: 0.3780 - val_accuracy: 0.8969\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3874 - accuracy: 0.8931 - val_loss: 0.3728 - val_accuracy: 0.8979\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3823 - accuracy: 0.8946 - val_loss: 0.3677 - val_accuracy: 0.8986\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3777 - accuracy: 0.8952 - val_loss: 0.3629 - val_accuracy: 0.8999\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3732 - accuracy: 0.8964 - val_loss: 0.3595 - val_accuracy: 0.9005\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3691 - accuracy: 0.8968 - val_loss: 0.3557 - val_accuracy: 0.9025\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3652 - accuracy: 0.8973 - val_loss: 0.3519 - val_accuracy: 0.9026\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3616 - accuracy: 0.8984 - val_loss: 0.3485 - val_accuracy: 0.9030\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3581 - accuracy: 0.8993 - val_loss: 0.3453 - val_accuracy: 0.9042\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3548 - accuracy: 0.8996 - val_loss: 0.3419 - val_accuracy: 0.9044\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3517 - accuracy: 0.9003 - val_loss: 0.3391 - val_accuracy: 0.9050\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3487 - accuracy: 0.9013 - val_loss: 0.3360 - val_accuracy: 0.9053\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3459 - accuracy: 0.9021 - val_loss: 0.3334 - val_accuracy: 0.9056\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3432 - accuracy: 0.9026 - val_loss: 0.3315 - val_accuracy: 0.9060\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3406 - accuracy: 0.9034 - val_loss: 0.3286 - val_accuracy: 0.9069\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3381 - accuracy: 0.9039 - val_loss: 0.3261 - val_accuracy: 0.9069\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3358 - accuracy: 0.9046 - val_loss: 0.3247 - val_accuracy: 0.9075\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3335 - accuracy: 0.9052 - val_loss: 0.3219 - val_accuracy: 0.9092\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3313 - accuracy: 0.9054 - val_loss: 0.3197 - val_accuracy: 0.9092\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3291 - accuracy: 0.9061 - val_loss: 0.3178 - val_accuracy: 0.9088\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3270 - accuracy: 0.9064 - val_loss: 0.3160 - val_accuracy: 0.9089\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3250 - accuracy: 0.9068 - val_loss: 0.3143 - val_accuracy: 0.9103\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3231 - accuracy: 0.9075 - val_loss: 0.3129 - val_accuracy: 0.9105\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3213 - accuracy: 0.9079 - val_loss: 0.3107 - val_accuracy: 0.9107\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3194 - accuracy: 0.9086 - val_loss: 0.3095 - val_accuracy: 0.9118\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3177 - accuracy: 0.9086 - val_loss: 0.3076 - val_accuracy: 0.9123\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3160 - accuracy: 0.9096 - val_loss: 0.3056 - val_accuracy: 0.9132\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3143 - accuracy: 0.9098 - val_loss: 0.3043 - val_accuracy: 0.9123\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3127 - accuracy: 0.9103 - val_loss: 0.3031 - val_accuracy: 0.9130\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3112 - accuracy: 0.9106 - val_loss: 0.3010 - val_accuracy: 0.9142\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3095 - accuracy: 0.9115 - val_loss: 0.3009 - val_accuracy: 0.9143\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3082 - accuracy: 0.9117 - val_loss: 0.2987 - val_accuracy: 0.9145\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3066 - accuracy: 0.9118 - val_loss: 0.2974 - val_accuracy: 0.9144\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3052 - accuracy: 0.9123 - val_loss: 0.2960 - val_accuracy: 0.9147\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3038 - accuracy: 0.9127 - val_loss: 0.2949 - val_accuracy: 0.9149\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3025 - accuracy: 0.9132 - val_loss: 0.2930 - val_accuracy: 0.9152\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3011 - accuracy: 0.9131 - val_loss: 0.2926 - val_accuracy: 0.9159\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2998 - accuracy: 0.9139 - val_loss: 0.2914 - val_accuracy: 0.9156\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2985 - accuracy: 0.9143 - val_loss: 0.2896 - val_accuracy: 0.9164\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2973 - accuracy: 0.9143 - val_loss: 0.2888 - val_accuracy: 0.9167\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2960 - accuracy: 0.9149 - val_loss: 0.2875 - val_accuracy: 0.9168\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2948 - accuracy: 0.9152 - val_loss: 0.2863 - val_accuracy: 0.9171\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2936 - accuracy: 0.9154 - val_loss: 0.2854 - val_accuracy: 0.9171\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2924 - accuracy: 0.9158 - val_loss: 0.2850 - val_accuracy: 0.9180\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2914 - accuracy: 0.9160 - val_loss: 0.2833 - val_accuracy: 0.9186\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2902 - accuracy: 0.9161 - val_loss: 0.2827 - val_accuracy: 0.9186\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2891 - accuracy: 0.9163 - val_loss: 0.2813 - val_accuracy: 0.9182\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2880 - accuracy: 0.9168 - val_loss: 0.2805 - val_accuracy: 0.9187\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2869 - accuracy: 0.9166 - val_loss: 0.2794 - val_accuracy: 0.9194\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2859 - accuracy: 0.9170 - val_loss: 0.2786 - val_accuracy: 0.9196\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2848 - accuracy: 0.9174 - val_loss: 0.2779 - val_accuracy: 0.9198\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2838 - accuracy: 0.9176 - val_loss: 0.2767 - val_accuracy: 0.9201\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2828 - accuracy: 0.9181 - val_loss: 0.2758 - val_accuracy: 0.9198\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2818 - accuracy: 0.9178 - val_loss: 0.2749 - val_accuracy: 0.9202\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2808 - accuracy: 0.9182 - val_loss: 0.2745 - val_accuracy: 0.9214\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2798 - accuracy: 0.9186 - val_loss: 0.2732 - val_accuracy: 0.9215\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2789 - accuracy: 0.9190 - val_loss: 0.2721 - val_accuracy: 0.9214\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2779 - accuracy: 0.9192 - val_loss: 0.2711 - val_accuracy: 0.9212\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2770 - accuracy: 0.9194 - val_loss: 0.2705 - val_accuracy: 0.9218\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2760 - accuracy: 0.9199 - val_loss: 0.2701 - val_accuracy: 0.9222\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2751 - accuracy: 0.9198 - val_loss: 0.2692 - val_accuracy: 0.9226\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2741 - accuracy: 0.9200 - val_loss: 0.2687 - val_accuracy: 0.9216\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2733 - accuracy: 0.9203 - val_loss: 0.2673 - val_accuracy: 0.9231\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2724 - accuracy: 0.9208 - val_loss: 0.2667 - val_accuracy: 0.9229\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2715 - accuracy: 0.9207 - val_loss: 0.2657 - val_accuracy: 0.9230\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2706 - accuracy: 0.9213 - val_loss: 0.2648 - val_accuracy: 0.9233\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2697 - accuracy: 0.9217 - val_loss: 0.2644 - val_accuracy: 0.9241\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2689 - accuracy: 0.9216 - val_loss: 0.2635 - val_accuracy: 0.9233\n",
            "[INFO] evaluating network...\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       980\n",
            "           1       0.97      0.97      0.97      1135\n",
            "           2       0.92      0.90      0.91      1032\n",
            "           3       0.90      0.91      0.91      1010\n",
            "           4       0.92      0.93      0.93       982\n",
            "           5       0.90      0.86      0.88       892\n",
            "           6       0.93      0.95      0.94       958\n",
            "           7       0.93      0.92      0.93      1028\n",
            "           8       0.89      0.89      0.89       974\n",
            "           9       0.91      0.90      0.90      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "The predicted value is 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# define the 784-256-128-10 architecture using Keras\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"sigmoid\"))\n",
        "model.add(Dense(128, activation=\"sigmoid\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "# train the model using SGD\n",
        "print(\"[INFO] training network...\")\n",
        "sgd = SGD(0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
        "metrics=[\"accuracy\"])\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
        "epochs=100, batch_size=128)\n",
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=128)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "predictions.argmax(axis=1),\n",
        "target_names=[str(x) for x in lb.classes_]))\n",
        "# plot the training loss and accuracy\n",
        "import random\n",
        "\n",
        "for i in range(0,9):\n",
        "  r = random.randint(0,100)\n",
        "\n",
        "plt.imshow(xtest[r])\n",
        "\n",
        "prediction = model.predict(testX)\n",
        "print(f\"The predicted value is {np.argmax(prediction[r])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJGy70tgTLki"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPFSe+pwMyOhtBgvpwx9OCY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}